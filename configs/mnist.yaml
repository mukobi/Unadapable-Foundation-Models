# General
seed: 0
model: MLP
pretrained: False

# Pretraining
pretrain:
  dataset: MNIST
  epochs: 8
  lr: 0.001
  batch_size: 128
  test_batch_size: 1000

# Finetuning
finetune:
  dataset: FashionMNIST
  epochs: 1
  lr: 0.001
  batch_size: 128
  test_batch_size: 1000

# Unadaptability methods
unadapt:
  # - method: 'prune'
  #   prune_percentage: 0.7
  # - method: 'rescale'
  #   rescale_factor: 1000000
  - method: 'gradient'
    loss: 'hessian_trace'
    lam: 0.1
    lr: 0.001
    gamma: 0.7
    epochs: 1